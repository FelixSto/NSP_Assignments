{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Problem 2 - Keyword Recognition\n",
    "\n",
    "In this notebook you can train a CNN model for keyword recognition. Parts of the notebook are inspired by [this nice\n",
    "tutorial](https://pytorch.org/tutorials/intermediate/speech_command_recognition_with_torchaudio.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from matplotlib import cm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.models.keyword_cnn import KeyWordCNN1d,  KeyWordCNN2d\n",
    "from src.utils.plotting import init_plot_style\n",
    "init_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data. Make sure you have downloaded and extracted the dataset in\n",
    "`project-root/data/audio/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.speech_commands_data import SpeechCommandsData\n",
    "\n",
    "scdata = SpeechCommandsData()\n",
    "\n",
    "# create training, validation and test sets\n",
    "train_set = scdata.get_subset('training')\n",
    "print(f'We have {len(train_set)} samples in the training set.')\n",
    "validation_set = scdata.get_subset('validation')\n",
    "print(f'We have {len(validation_set)} samples in the validation set.')\n",
    "test_set = scdata.get_subset('testing')\n",
    "print(f'We have {len(test_set)} samples in the testing set.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the dataset. A data point is a tuple made of a waveform\n",
    "(the audio signal), the sample rate, the utterance (label), the ID of\n",
    "the speaker, the number of the utterance. We can also plot and listen to an example recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[2]\n",
    "\n",
    "print(f'The shape of the waveform is {waveform.shape}.')\n",
    "print(f'The sample rate of the waveform is {sample_rate}.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(waveform.T.numpy())\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In our setup we do not feed the raw waveform directly in to the CNN but we apply\n",
    "a preprocessing step beforehand. Specifically, we compute a (variable length) sequence of\n",
    "40 log Mel Frequency Cepstral Coefficients (MFCCs) for each waveform. Below we define the\n",
    "transform, apply it on an example waveform an plot the resulting lMFCC spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mfcc_transform = torchaudio.transforms.MFCC(sample_rate, log_mels=True)\n",
    "mfcc_sequence = mfcc_transform(waveform)\n",
    "print(f'The shape of the MFCC feature sequence is {mfcc_sequence.shape}')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.imshow(mfcc_sequence.squeeze(), cmap=cm.coolwarm, origin='lower')\n",
    "plt.colorbar(cax)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to extract the labels (the keywords) from the dataset. For the implementation\n",
    "we assign each keyword a unique index (number) representing the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mappings from labels to indices and vice versa\n",
    "labels = scdata.labels\n",
    "label_to_index = lambda label: torch.tensor(labels.index(label))\n",
    "index_to_label = lambda index: labels[index]\n",
    "\n",
    "print(f'There are {len(labels)} different utterances in the dataset, i.e. ' + repr(labels))\n",
    "print('Mapping from label to index: ' + str(label_to_index('go')))\n",
    "print('Mapping from index to label: ' + index_to_label(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our model and see how many parameters it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = KeyWordCNN1d()\n",
    "# model = KeyWordCNN2d()\n",
    "\n",
    "\n",
    "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model)} trainable parameters.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our training and test epoch functions. You could also include\n",
    "a validation epoch (instead of the test epoch) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, epoch, log_interval):\n",
    "    model.train() # puts the model into train model\n",
    "\n",
    "    loss_list = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # apply the mfcc transform on the data and compute model output\n",
    "        data = mfcc_transform(data).squeeze(1)\n",
    "        output = model(data)\n",
    "\n",
    "        # compute the negative log-likelihood and update parameters\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Training epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} samples'\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.4f}')\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    return loss_list\n",
    "\n",
    "def test_epoch(model, epoch):\n",
    "    model.eval() # puts the model into eval mode\n",
    "\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # apply the mfcc transform on the data and compute model output\n",
    "        data = mfcc_transform(data).squeeze(1)\n",
    "        output = model(data)\n",
    "\n",
    "        # count correct predictions\n",
    "        predicted_targets = output.argmax(-1)\n",
    "        correct += predicted_targets.eq(target).sum().item()\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setup\n",
    "log_interval = 20 # log training stats after so many batches\n",
    "num_epochs = 2 # number of epochs (cycles through the whole training set)\n",
    "\n",
    "# create data loaders for the subsets\n",
    "batch_size = 256\n",
    "train_loader = scdata.get_dataloader(train_set, batch_size, shuffle=True)\n",
    "validation_loader = scdata.get_dataloader(validation_set, batch_size)\n",
    "test_loader = scdata.get_dataloader(test_set, batch_size)\n",
    "\n",
    "# define and parameterize the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# set up the progress bar\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "with tqdm(total=num_epochs) as pbar:\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss_list += train_epoch(model, optimizer, epoch, log_interval)\n",
    "        test_epoch(model, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "# Let's plot the training loss versus the number of iteration.\n",
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Batch Updates')\n",
    "plt.ylabel('Negative Log-Likelihood')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick out some example of the test set and see what our model predicts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(waveform):\n",
    "    \"\"\"Predict the label for the input waveform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waveform : torch.Tensor\n",
    "        The input waveform.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "        The predicted label.\n",
    "    \"\"\"\n",
    "    sequence = mfcc_transform(waveform)\n",
    "    pred = model(sequence).argmax(-1)\n",
    "    return index_to_label(pred.squeeze())\n",
    "\n",
    "\n",
    "waveform, sample_rate, utterance, *_ = test_set[1]\n",
    "print(f\"Expected: {utterance}. Predicted: {predict_word(waveform)}.\")\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be insightful to have a look at the confusion matrix of your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((len(labels), len(labels)))\n",
    "for i, (waveform, _, utterance, *_) in enumerate(test_set):\n",
    "    output = predict_word(waveform)\n",
    "    confusion_matrix[label_to_index(output), label_to_index(utterance)] += 1\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}