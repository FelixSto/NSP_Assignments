{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 1\n",
    "## Problem 1 - System Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "# from src.models.mls_models import MyFancyModel\n",
    "from src.utils.plotting import init_plot_style\n",
    "%pylab\n",
    "\n",
    "init_plot_style()\n",
    "data_dir='../../data/csv/1_1_system_identification/'\n",
    "\n",
    "warnings.filterwarnings('ignore') # Supress warnings from polyfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(data_dir + 'training-set.csv').to_numpy()\n",
    "x_train, y_train = training_set[:,0], training_set[:,1]\n",
    "\n",
    "test_set = pd.read_csv(data_dir + 'test-set.csv').to_numpy()\n",
    "x_test, y_test = test_set[:,0], test_set[:,1]\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'x', label='Training Set')\n",
    "plt.plot(x_test, y_test, '^', label='Test Set')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run your experiments from here on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defenition of some functions for Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the MSE of the given coefficents p\n",
    "\n",
    "def MSE(p,x,y):\n",
    "        \"\"\"Computing the 1D-MSE, given the polynomial coefficents p, the places x and the data y  \"\"\"\n",
    "        y_hat = np.polyval(p,x) \n",
    "        error = (y_hat-y)**2    \n",
    "        mse = np.mean(error)\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "# Evaluate the polynomial model\n",
    "    \n",
    "def PolyModelEval(order, x_fit, y_fit, x):\n",
    "        \"\"\"Evaluate the poly model, fited to the data [x_fit, y_fit] at x\"\"\"\n",
    "        p = np.polyfit(x_fit, y_fit, order, full=False)\n",
    "        y_hat = np.polyval(p,x)\n",
    "        return y_hat\n",
    "    \n",
    "# For RBF linear least squares solution\n",
    "\n",
    "def RbfOptimizer(P, w, x):\n",
    "        \"\"\"Compute the matrix A for finding the linear least squares solution based on the data x.\"\"\"\n",
    "        rbf_center = np.arange(0,1,1/P)\n",
    "        A = np.ones([np.size(x), P])\n",
    "        \n",
    "        for i in range(0,np.size(x)):\n",
    "            for j in range(1,P):\n",
    "                A[i,j] = e**(-(x[i]-rbf_center[j])**2/w)\n",
    "        return A\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:2.2px solid Black'></hr>\n",
    "\n",
    "**Task a)** Find a suitable polynomial model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First test just with polyfit\n",
    "\n",
    "P_max = 25\n",
    "residuals_train = np.zeros(P_max-1)\n",
    "residuals_test = np.zeros(P_max-1)\n",
    "\n",
    "for order in range(1,P_max):\n",
    "    \n",
    "    p = np.polyfit(x_train, y_train, order, full=False)\n",
    "    residuals_train[order-1] = MSE(p,x_train, y_train)\n",
    "    residuals_test[order-1] = MSE(p,x_test, y_test)\n",
    "    \n",
    "train_min = np.where(residuals_train == np.amin(residuals_train)) #optimal order\n",
    "test_min = np.where(residuals_test == np.amin(residuals_test))    #optimal order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal polynomial order for training set:  [23] with MSE:  [0.02241836]\n",
      "Optimal polynomial order for test set:  [20] with MSE:  [0.04568998]\n"
     ]
    }
   ],
   "source": [
    "#Plot of MSE for train and test\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1,P_max),residuals_train, label='Training Set')\n",
    "plt.plot(np.arange(1,P_max), residuals_test, label='Test Set')\n",
    "plt.legend()\n",
    "plt.xlabel('Polynomial order P')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Optimal polynomial order for training set: ', train_min[0]+1, 'with MSE: ', residuals_train[train_min[0]])\n",
    "print('Optimal polynomial order for test set: ', test_min[0]+1, 'with MSE: ', residuals_test[test_min[0]])\n",
    "\n",
    "#Plot the optimal model with training/test set\n",
    "\n",
    "x_eval = np.arange(0,1,0.005)\n",
    "opt_train_model = PolyModelEval(train_min[0]+1, x_train, y_train, x_eval)\n",
    "opt_test_model = PolyModelEval(test_min[0]+1, x_train, y_train, x_eval)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x_train, y_train, 'x', label='Training Set')\n",
    "plt.plot(x_test, y_test, '^', label='Test Set')\n",
    "plt.plot(x_eval, opt_train_model, label='Optimal Training Model')\n",
    "plt.plot(x_eval, opt_test_model, label='Optimal Test Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='border:2.2px solid Black'></hr>\n",
    "\n",
    "**Task b)** Use a subset of the original training set as validation set. Training and validation set must be disjoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV_ratio = 0.3 #Define splitting ratio btw. training and validation set, in [0,1]\n",
    "\n",
    "N_sample = size(x_train)\n",
    "Val_size = np.ceil(N_sample*TV_ratio)\n",
    "\n",
    "rng = default_rng()\n",
    "pos = rng.choice(N_sample,Val_size.astype(int), replace=False) #Draw non-repetitive random numbers\n",
    "\n",
    "x_validation = x_train[pos]\n",
    "y_validation = y_train[pos]\n",
    "\n",
    "x_train2 = np.delete(x_train, pos)\n",
    "y_train2 = np.delete(y_train, pos)\n",
    "\n",
    "# Plot the splitted data-set\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x_train2, y_train2, 'x', label='Training Set')\n",
    "plt.plot(x_test, y_test, '^', label='Test Set')\n",
    "plt.plot(x_validation, y_validation, 'o', label='Validation Set')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation based on validation set performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal polynomial order for validation set:  [16] with MSE:  [0.12705467]\n",
      "Optimal polynomial order for test set:  [15] with MSE:  [0.05526431]\n"
     ]
    }
   ],
   "source": [
    "P_max = 30\n",
    "\n",
    "residuals_validation = np.zeros(P_max-1)\n",
    "residuals_train = np.zeros(P_max-1)\n",
    "residuals_test = np.zeros(P_max-1)\n",
    "\n",
    "for order in range(1,P_max):\n",
    "    \n",
    "    p = np.polyfit(x_train2, y_train2, order, full=False)\n",
    "    residuals_train[order-1] = MSE(p,x_train2, y_train2)\n",
    "    residuals_validation[order-1] = MSE(p,x_validation, y_validation)\n",
    "    residuals_test[order-1] = MSE(p,x_test, y_test)\n",
    "    \n",
    "validation_min = np.where(residuals_validation == np.amin(residuals_validation)) #optimal order\n",
    "test_min = np.where(residuals_test == np.amin(residuals_test))\n",
    "\n",
    "print('Optimal polynomial order for validation set: ', validation_min[0]+1, 'with MSE: ', residuals_validation[validation_min[0]])\n",
    "print('Optimal polynomial order for test set: ', test_min[0]+1, 'with MSE: ', residuals_test[test_min[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training and validation MSE curve\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1,P_max),residuals_train, label='Training Set')\n",
    "plt.plot(np.arange(1,P_max), residuals_validation, label='Validation Set')\n",
    "plt.xlabel('Polynomial order P')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Comparision training and validation MSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#Plot of the optimal model based on test set\n",
    "\n",
    "x_eval = np.arange(0,1,0.01)\n",
    "y_opt_model = PolyModelEval(test_min[0]+1, x_train2, y_train2, x_eval)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x_train2, y_train2, 'x', label='Training Set')\n",
    "plt.plot(x_test, y_test, 'o', label='Test Set')\n",
    "plt.plot(x_eval, y_opt_model, label='Optimal Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Optimal Test Model')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;\n",
    "<hr style='border:2.2px solid Black'></hr>\n",
    "\n",
    "**Task c)** Use a Gaussian radial basis ($RBF$) function model $\\hat{f}$\n",
    "\n",
    "$\\hat{f}(x) = \\alpha_0 + \\sum_{p=1}^{P} \\alpha_p e^{\\frac{-(x-c_p)^2}{2\\omega_p^2}}$\n",
    "\n",
    "To avoid the nonlinearity, the centers of the P $RBF$ are choosen evenly spaced on the support of the given data.\n",
    "\n",
    "The coefficent vector $c_{opt}$ is determined by means of minimizing the MSE for thge given model oder P:\n",
    "\n",
    "$\n",
    "c_{opt} = (A^TA)^{-1} \\cdot A^T y_{train}\n",
    "$\n",
    "\n",
    "Where $A$ is defined as:\n",
    "&ensp;\n",
    "\n",
    "$\n",
    "A = \\begin{bmatrix}\n",
    "1 & e^{\\frac{-(x[0]-c_1)^2}{2\\omega^2}} & e^{\\frac{-(x[1]-c_1)^2}{2\\omega^2}} & \\dots & e^{\\frac{-(x[N]-c_1)^2}{2\\omega^2}}\\\\\n",
    "1 & e^{\\frac{-(x[0]-c_2)^2}{2\\omega^2}} & e^{\\frac{-(x[1]-c_2)^2}{2\\omega^2}} & \\dots & e^{\\frac{-(x[N]-c_2)^2}{2\\omega^2}}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "1 & e^{\\frac{-(x[0]-c_P)^2}{2\\omega^2}} & e^{\\frac{-(x[1]-c_P)^2}{2\\omega^2}} & \\dots &  e^{\\frac{-(x[N]-c_P)^2}{2\\omega^2}}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "&ensp;\n",
    "&ensp;\n",
    "&ensp;\n",
    "&ensp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set:  0.04439075617460967\n"
     ]
    }
   ],
   "source": [
    "P = 20 #number of RBF's\n",
    "\n",
    "rbf_center = np.arange(0,1,1/P)\n",
    "w2 = (2/P)**2 #width parameter sqared\n",
    "\n",
    "A = RbfOptimizer(P, w2, x_train)     \n",
    "c_opt = np.linalg.pinv(A).dot(y_train)\n",
    "\n",
    "#Evaluate the model with test set\n",
    "\n",
    "y_hat = RbfOptimizer(P, w2, x_test).dot(c_opt)  #for MSE compuation\n",
    "mse = np.mean((y_hat-y_test)**2)  \n",
    "\n",
    "print('MSE on test set: ', mse)\n",
    "\n",
    "x_eval = np.arange(0,1,0.01)\n",
    "y_eval = RbfOptimizer(P, w2, x_eval).dot(c_opt) #for plot\n",
    "\n",
    "#Plot the model for the selected model order P\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x_train2, y_train2, 'x', label = 'Training Set')\n",
    "plt.plot(x_test, y_test, 'o', label='Test Set')\n",
    "plt.plot(x_eval, y_eval, label = ' RBF Model')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal RBF order for test set:  [20] with MSE:  [[0.04439076]]\n"
     ]
    }
   ],
   "source": [
    "#Just some code to find the optimal model order P, not asked!\n",
    "P = 35 #number of RBF's\n",
    "\n",
    "mse = np.zeros([P-1,1])\n",
    "\n",
    "for order in range(1,P):\n",
    "    \n",
    "    w2 = (2/order)**2                    #width parameter sqared\n",
    "    rbf_center = np.arange(0,1,1/order)  #RBF centers\n",
    "    \n",
    "    A = RbfOptimizer(order, w2, x_train)     \n",
    "    c_opt = np.linalg.pinv(A).dot(y_train)\n",
    "    \n",
    "    y_hat = RbfOptimizer(order, w2, x_test).dot(c_opt)\n",
    "    mse[order-1] = np.mean((y_hat-y_test)**2)  \n",
    "    \n",
    "mse_min = np.where(mse == np.amin(mse)) #optimal order\n",
    "print('Optimal RBF order for test set: ', mse_min[0]+1, 'with MSE: ', mse[mse_min[0]])\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(0,P-1,1), mse)\n",
    "plt.xlabel('RBF order')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;\n",
    "\n",
    "<hr style='border:2.2px solid Black'></hr>\n",
    "\n",
    "**Task d)** Learn the optimal centers and widths using gradient descent (GD). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
