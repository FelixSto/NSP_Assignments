{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Identification of Fading Memory Nonlinearities\n",
    "\n",
    "We will revisit the problem of system identification and have a look at an example where we use a simple\n",
    "convolutional neural network to model our unknown system.\n",
    "\n",
    "## What is System Identification?\n",
    "The general setup for system identification is depicted in the figure below. We observe an input signal $x[n]$ and\n",
    "corresponding measurements $y[n]$ of the system's output $f(x[n], x[n-1], \\dots, y[n-1], y[n-2], \\dots)$ that are corrupted by measurement noise $\\nu[n]$.\n",
    "The goal of system identification is now to find an approximate system $\\hat{f}(\\cdot)$ that \"behaves as similarly as\n",
    "possible to the true system $f(\\cdot)$\".\n",
    "\n",
    "<img src=\"../../data/figures/system-identification.png\" alt=\"System Identification Schematic\" width=\"600\" />\n",
    "\n",
    "What does \"as similar as possible\" actually mean? We can characterize the approximation quality by considering\n",
    "(functions of) the error signal $e[n] = \\hat{y}[n] - y[n]$. Here we will use a standard measure, the mean squared error\n",
    "(MSE) $J = \\frac{1}{N} \\sum_{n=1}^N e[n]^2$, that comes as a natural consequence when we assume that the noise $\\nu$\n",
    " is normally distributed. See the class notes for more details.\n",
    "\n",
    "**Importantly, be aware that we make several assumptions here:**\n",
    " - The system $f(\\cdot)$ is deterministic.\n",
    " - The measurements $y[n]$ are corrupted with additive noise, whereas they could arbitrarily depend on the noise!\n",
    " - We assume that $x[n]$ and $y[n]$ are scalars.\n",
    "\n",
    "We will further assume that $f(\\cdot)$ is a static (memory-less) nonlinearity.\n",
    "\n",
    "So let's get started. First, we need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import hankel\n",
    "\n",
    "from src.models.simple_cnn import SimpleCNN\n",
    "from src.utils.plotting import init_plot_style\n",
    "%pylab\n",
    "\n",
    "# initialize our global plot style\n",
    "init_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We create our true system that we want to identify later on and plot the system response for a random test signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def system(x):\n",
    "    \"\"\"Implements a deterministic, fading memory nonlinearity.\n",
    "\n",
    "    To generate an output of equal length as the input signal we apply zero-padding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float or numpy.ndarray\n",
    "        The systems input.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    float or numpy.ndarray\n",
    "        The corresponding system output.\n",
    "    \"\"\"\n",
    "    mem_depth = 5\n",
    "    weights = np.array([0.1, 0.5, 1.4, 5.3, 3.2])\n",
    "    padded_x = np.concatenate((np.zeros(mem_depth - 1,), x))\n",
    "    X = hankel(padded_x[:mem_depth], padded_x[mem_depth-1:])\n",
    "    X[0,:] = (X[0,:] - X[4,:])**2\n",
    "    X[1,:] = np.exp(X[1,:] - X[2,:])\n",
    "    X[2,:] = np.sqrt(np.abs(X[2,:]))\n",
    "    X[3,:] = X[3,:]**3\n",
    "    X[4,:] = np.log(np.abs(X[4,:]) + 1e-3)\n",
    "    return weights.dot(X)\n",
    "\n",
    "\n",
    "# sample support and compute system output\n",
    "n_samples = 50\n",
    "test_signal = np.random.uniform(0, 1, n_samples)\n",
    "# test_signal = np.cos(0.1*np.pi*np.arange(n_samples))\n",
    "test_output = system(test_signal)\n",
    "\n",
    "# plot the input/output behavior\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "plt.plot(test_signal, label='Test Input, $x[n]$')\n",
    "plt.plot(test_output, label='Test Output, $y[n]$')\n",
    "plt.xlabel('Time Index, $n$')\n",
    "plt.ylabel('$x[n]$, $y[n]$')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate a training and test set by generating random test signals,\n",
    "propagating them over the system and corrupting them with additive white Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_train = 500 # length of training signals\n",
    "n_test = 200 # length of test signals\n",
    "nu = 0.4\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "x_train = rng.uniform(size=n_train) * 2.0 - 1.0 # draw samples from support\n",
    "noise = rng.normal(loc=0, scale=nu, size=n_train) # generate noise\n",
    "y_train = system(x_train) + noise # simulate measurements\n",
    "\n",
    "x_test = rng.uniform(size=n_test) * 2.0 - 1.0 # draw samples from support\n",
    "noise = rng.normal(loc=0, scale=nu, size=n_test) # generate noise\n",
    "y_test = system(x_test) + noise # simulate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are now ready to fit our simple neural network to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create and fit an instance of our simple CNN model given our training data\n",
    "cnn_model = SimpleCNN(num_kernels=5, mem_depth=5)\n",
    "train_loss_list, val_loss_list = cnn_model.fit(x_train, y_train, learning_rate=1e-1, max_epochs=500)\n",
    "\n",
    "# plot the evolution of the training MSE\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "plt.plot(list(range(1, 1 + len(train_loss_list))), train_loss_list)\n",
    "plt.plot(list(range(1, 1 + len(val_loss_list))), val_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Set MSE')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we plot the predicted training and test outputs with their respective ground truths."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "prediction = cnn_model(x_train).detach().squeeze().numpy()\n",
    "train_mse = np.mean((prediction - y_train)**2)\n",
    "print(f'Training MSE is {train_mse}.')\n",
    "plt.figure()\n",
    "plt.plot(y_train, label='True Training Output, $y[n]$')\n",
    "plt.plot(prediction, label=r'Predicted Output, $\\hat{y}[n]$')\n",
    "plt.xlabel('Time Index, $n$')\n",
    "plt.ylabel(r'$y[n]$, $\\hat{y}[n]$')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "prediction = cnn_model(x_test).detach().squeeze().numpy()\n",
    "test_mse = np.mean((prediction - y_test)**2)\n",
    "print(f'Test MSE is {test_mse}.')\n",
    "plt.figure()\n",
    "plt.plot(y_test, label='True Test Output, $y[n]$')\n",
    "plt.plot(prediction, label=r'Predicted Output, $\\hat{y}[n]$')\n",
    "plt.xlabel('Time Index, $n$')\n",
    "plt.ylabel(r'$y[n]$, $\\hat{y}[n]$')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}