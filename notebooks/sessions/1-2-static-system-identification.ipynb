{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Identification of Static Nonlinearities\n",
    "\n",
    "We will define the problem of system identification and have a look at a simple example where we use a simple\n",
    "feed-forward neural network to model our unknown system.\n",
    "\n",
    "## What is System Identification?\n",
    "The general setup for system identification is depicted in the figure below. We observe an input signal $x[n]$ and\n",
    "corresponding measurements $y[n]$ of the system's output $f(x[n])$ that are corrupted by measurement noise $\\nu[n]$.\n",
    "The goal of system identification is now to find an approximate system $\\hat{f}(\\cdot)$ that \"behaves as similarly as\n",
    "possible to the true system $f(\\cdot)$\".\n",
    "\n",
    "<img src=\"../../data/figures/system-identification.png\" alt=\"System Identification Schematic\" width=\"600\" />\n",
    "\n",
    "What does \"as similar as possible\" actually mean? We can characterize the approximation quality by considering\n",
    "(functions of) the error signal $e[n] = \\hat{y}[n] - y[n]$. Here we will use a standard measure, the mean squared error\n",
    "(MSE) $J = \\frac{1}{N} \\sum_{n=1}^N e[n]^2$, that comes as a natural consequence when we assume that the noise $\\nu$\n",
    " is normally distributed. See the class notes for more details.\n",
    "\n",
    "**Importantly, be aware that we make several assumptions here:**\n",
    " - The system $f(\\cdot)$ is deterministic.\n",
    " - The measurements $y[n]$ are corrupted with additive noise, whereas they could arbitrarily depend on the noise!\n",
    " - We assume that $x[n]$ and $y[n]$ are scalars.\n",
    "\n",
    "We will further assume that $f(\\cdot)$ is a static (memory-less) nonlinearity.\n",
    "\n",
    "So let's get started. First, we need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.models.simple_mlp import SimpleMLP\n",
    "from src.utils.plotting import init_plot_style\n",
    "\n",
    "# initialize our global plot style\n",
    "init_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we create our true system that we want to identify later on and plot its input/output response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def system(x):\n",
    "    \"\"\"Implements a deterministic, static nonlinearity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float or numpy.ndarray\n",
    "        The systems input.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    float or numpy.ndarray\n",
    "        The corresponding system output.\n",
    "    \"\"\"\n",
    "    y = np.ones_like(x)\n",
    "    y[np.abs(x) < 0.25] = 0\n",
    "    y[np.abs(x) > 0.75] = 0\n",
    "    return y\n",
    "\n",
    "# sample support and compute system output\n",
    "support = np.linspace(-1, 1, 100)\n",
    "true_output = system(support)\n",
    "\n",
    "# plot the input/output behavior\n",
    "plt.figure()\n",
    "plt.plot(support, true_output)\n",
    "plt.xlabel('Input, $x$')\n",
    "plt.ylabel('Output, $y$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate a training and test set by drawing samples uniformly at random from the system's support,\n",
    "propagating them over the system and corrupting them with additive white Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_train = 50 # number of training samples\n",
    "n_test = 20 # number of test samples\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "x_train = rng.uniform(size=n_train) * 2.0 - 1.0 # draw samples from support\n",
    "noise = rng.normal(loc=0, scale=0.1, size=n_train) # generate noise\n",
    "y_train = system(x_train) + noise # simulate measurements\n",
    "\n",
    "x_test = rng.uniform(size=n_test) * 2.0 - 1.0 # draw samples from support\n",
    "noise = rng.normal(loc=0, scale=0.1, size=n_test) # generate noise\n",
    "y_test = system(x_test) + noise # simulate measurements\n",
    "\n",
    "# plot the true system's response with training and test samples\n",
    "plt.figure()\n",
    "plt.plot(support, true_output, label='True System')\n",
    "plt.plot(x_train, y_train, 'x', label='Training Samples')\n",
    "plt.plot(x_test, y_test, 'x', label='Test Samples')\n",
    "plt.xlabel('Input, $x$')\n",
    "plt.ylabel('Output, $y$')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are now ready to fit our simple neural network to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create and fit an instance of our simple MLP model given our training data\n",
    "mlp_model = SimpleMLP(hidden_size=32)\n",
    "loss_list = mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# plot the evolution of the training MSE\n",
    "plt.figure()\n",
    "plt.plot(list(range(1, 1 + len(loss_list))), loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Set MSE')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us also compare the input/output response of the system to the true system and see how it performs on unseen\n",
    "samples from our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute the approximated system behavior and the prediction for our test set\n",
    "approx_output = mlp_model.predict(support)\n",
    "y_pred = mlp_model.predict(x_test)\n",
    "\n",
    "print(f'Training MSE is {loss_list[-1]:.2f}')\n",
    "print(f'Test MSE is {np.mean((y_test - y_pred)**2):.2f}')\n",
    "\n",
    "# plot the true and approximated systems with the test samples\n",
    "plt.figure()\n",
    "plt.plot(support, true_output, label='True System')\n",
    "plt.plot(support, approx_output, label='Approximated System (MLP)')\n",
    "plt.plot(x_test, y_test, 'x', label='Test Samples')\n",
    "plt.xlabel('Input, $x$')\n",
    "plt.ylabel('Output, $y$')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Simple as that - we did our first system identification with a simple feed-forward neural network!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}